{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using PyCaret for banrkuptcy classification from [kaggle dataset](https://www.kaggle.com/c/mgmt571/overview):"
      ],
      "metadata": {
        "id": "c0GerEyoSbe4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Install Pycaret package**"
      ],
      "metadata": {
        "id": "EJRb8gdDTU5Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2uBagQS1HSPh"
      },
      "outputs": [],
      "source": [
        "!pip install pycaret"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Dowloading dataset and applying PyCaret**\n",
        "\n",
        "\\\n",
        "The first problem of our dataset is that it is highly imbalanced with disproportionally small number of bankrupt firms and overall small dataset, so we should apply SMOTE. Moreover, many of our features come from financial calculations using similar variables, so we need to lessen the overlap between them by removing multicollinearity to some degree. Also, to avoid overfitting, we should use fewer features by applying feature selection with LightGBM."
      ],
      "metadata": {
        "id": "idPk7kJdTc8x"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PFxVQcmkFIvJ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pycaret.classification import *\n",
        "\n",
        "\n",
        "# load data\n",
        "dataset = pd.read_csv('/content/bankruptcy_Train.csv')\n",
        "\n",
        "clf1 = setup(data = dataset, target = dataset.columns[-1], session_id = 123, fix_imbalance=True, fix_imbalance_method='smote', normalize=True, remove_multicollinearity=True, transformation=True, feature_selection=True)\n",
        "best_model = compare_models()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The results are pretty frustrating as dummy classification yields the best result. It is equal to saying that no company will go bankrupt. However, not surprisingly, the second model is XGBoost. In future, we can check our results with larger and more proportional dataset."
      ],
      "metadata": {
        "id": "tflIGt-OWp2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tuning our XGBoost model** \\\n",
        "With larger dataset in the future, we will replace XGBoost with just best_model"
      ],
      "metadata": {
        "id": "nrjV8_1mWdWr"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "11xt-dZuKGSQ"
      },
      "outputs": [],
      "source": [
        "model = create_model('xgboost')\n",
        "tuned_model = tune_model(model)\n",
        "final_model = finalize_model(tuned_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Out of curiosity, let's examine the parameters of our XGBoost model.**"
      ],
      "metadata": {
        "id": "Ragyl0wBaBcZ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0w-r_uY7MEBe"
      },
      "outputs": [],
      "source": [
        "evaluate_model(final_model)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Let's make a gradio app for the future datasets**"
      ],
      "metadata": {
        "id": "XwCvpSQ1amxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "create_app(final_model)"
      ],
      "metadata": {
        "id": "BHDrcif3jW1t"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}